{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuJkMMQxYXGM",
        "outputId": "afb25d2e-023e-4ebb-8657-0fc173ff5f68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WorkInTheDark/FairytaleQA_QAG_System.git\n",
        "%cd ./FairytaleQA_QAG_System/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvbJNPrmSsuQ"
      },
      "source": [
        "change the directory to the folder with separate story data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-O-hKuUSrJT"
      },
      "outputs": [],
      "source": [
        "\n",
        "dir = \"./split_for_training/train\"\n",
        "split_version = 'train'\n",
        "\n",
        "# dir = \"./split_for_training/test\"\n",
        "# split_version = 'test'\n",
        "\n",
        "# dir = \"./split_for_training/val\"\n",
        "# split_version = 'val'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJYsjgVjrS8U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from math import isnan\n",
        "import csv\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvs0GJVVrT9H"
      },
      "outputs": [],
      "source": [
        "def is_nan(x):\n",
        "    return isinstance(x, float) and isnan(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwCtbO_1rU26"
      },
      "outputs": [],
      "source": [
        "total_data = {}\n",
        "all_story_data = {}\n",
        "all_question_data = {}\n",
        "all_AC_input_data = {}\n",
        "all_QC_input_data = {}\n",
        "all_A_output_data = {}\n",
        "\n",
        "all_A1_output_data = {}\n",
        "all_A2_output_data = {}\n",
        "all_Q_input_data = {}\n",
        "all_C_input_data = {}\n",
        "all_spreadsheet_data = {}\n",
        "all_QS_input_data = {}\n",
        "all_CA_input_data = {}\n",
        "all_CQA_input_data = {}\n",
        "all_QAC_input_data = {}\n",
        "all_AC_ranking_input_data = {}\n",
        "all_QA_bias_analysis = {}\n",
        "\n",
        "all_QA_attribute = {}\n",
        "all_QA_ex_im = {}\n",
        "train_count = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I51g32w4uEDj",
        "outputId": "b1b3d2bc-448a-49be-ed85-1e98764fd006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====\n",
            "232 232\n",
            "cnt_files:  464\n",
            "# of books:  232\n"
          ]
        }
      ],
      "source": [
        "name_set = []\n",
        "csv_files = []\n",
        "\n",
        "cnt_files = 0\n",
        "for root, dirs, files in os.walk(dir):\n",
        "  if files == []:\n",
        "    continue\n",
        "  cnt_files += len(files)\n",
        "  for i in files:\n",
        "    if i.replace(\"-questions.csv\", \"\").replace(\"-story.csv\", \"\") not in name_set:\n",
        "      name_set.append( i.replace(\"-questions.csv\", \"\").replace(\"-story.csv\", \"\") )\n",
        "      csv_files.append(root + \"/\" + i.replace(\"-questions.csv\", \"\").replace(\"-story.csv\", \"\") + \"-story.csv\" )\n",
        "      \n",
        "\n",
        "print(\"====\")\n",
        "print(len(name_set), len(csv_files))\n",
        "print(\"cnt_files: \", cnt_files)\n",
        "\n",
        "assert len(name_set) == len(csv_files), print( len(name_set), len(csv_files) )\n",
        "print(\"# of books: \", len(name_set))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJr_Fw3RudgG"
      },
      "outputs": [],
      "source": [
        "cnt = 0\n",
        "cnt_q = 0\n",
        "\n",
        "\n",
        "for file_name in csv_files:\n",
        "\n",
        "  key = file_name.split(\"/\")[-1].replace(\"-questions.csv\", \"\").replace(\"-story.csv\", \"\")\n",
        "  \n",
        "\n",
        "  if key not in all_question_data:\n",
        "    all_question_data[key] = []\n",
        "    \n",
        "  if key not in all_AC_input_data:\n",
        "    all_AC_input_data[key] = []\n",
        "  \n",
        "  if key not in all_Q_input_data:\n",
        "    all_Q_input_data[key] = []\n",
        "  \n",
        "  if key not in all_C_input_data:\n",
        "    all_C_input_data[key] = []\n",
        "  \n",
        "  if key not in all_story_data:\n",
        "    all_story_data[key] = []\n",
        "  \n",
        "  if key not in all_QC_input_data:\n",
        "    all_QC_input_data[key] = []\n",
        "  \n",
        "  if key not in all_A_output_data:\n",
        "    all_A_output_data[key] = []\n",
        "\n",
        "  if key not in all_A1_output_data:\n",
        "    all_A1_output_data[key] = []\n",
        "  \n",
        "  if key not in all_A2_output_data:\n",
        "    all_A2_output_data[key] = []\n",
        "  \n",
        "  if key not in all_spreadsheet_data:\n",
        "    all_spreadsheet_data[key] = []\n",
        "\n",
        "  if key not in all_QS_input_data:\n",
        "    all_QS_input_data[key] = []\n",
        "\n",
        "  if key not in all_CA_input_data:\n",
        "    all_CA_input_data[key] = []\n",
        "\n",
        "  if key not in all_CQA_input_data:\n",
        "    all_CQA_input_data[key] = []\n",
        "  \n",
        "  if key not in all_QAC_input_data:\n",
        "    all_QAC_input_data[key] = []\n",
        "  \n",
        "  if key not in all_AC_ranking_input_data:\n",
        "    all_AC_ranking_input_data[key] = []\n",
        "  \n",
        "  if key not in all_QA_attribute:\n",
        "    all_QA_attribute[key] = []\n",
        "\n",
        "  if key not in all_QA_ex_im:\n",
        "    all_QA_ex_im[key] = []\n",
        "  \n",
        "  if key not in all_QA_bias_analysis:\n",
        "    all_QA_bias_analysis[key] = []\n",
        "    \n",
        "  print(key)\n",
        "  print(file_name)\n",
        "\n",
        "  total_data[key] = []\n",
        "\n",
        "  story_data = pd.read_csv(file_name).to_dict('index') \n",
        "  question_data = pd.read_csv( file_name.replace(\"-story.csv\", \"-questions.csv\") ).to_dict('index') \n",
        "\n",
        "  story_data_dict = {}\n",
        "\n",
        "  full_story = \"\"\n",
        "\n",
        "  for i in story_data:\n",
        "\n",
        "    if is_nan(story_data[i]['text']):\n",
        "      continue\n",
        "\n",
        "    try: \n",
        "\n",
        "      temp_data = story_data[i]['text'].replace('\\n',' ').replace('\\r',' ').replace('\\t',' ').replace('\\s',' ').replace('\\t+',' ').replace('\\s+',' ').lower()\n",
        "      temp_data = ' '.join(temp_data.split())\n",
        "\n",
        "      doc = nlp(temp_data)\n",
        "      tokenized = [token.text for token in doc]\n",
        "      temp_data = ' '.join(tokenized)\n",
        "\n",
        "      story_data_dict[int(story_data[i]['section'])] = temp_data\n",
        "      all_story_data[key].append( temp_data )\n",
        "      full_story += temp_data + ' <SEP> '\n",
        "\n",
        "      # <<<DEPRECATED>>> parsing code\n",
        "      # story_data_dict[int(story_data[i]['section'])] = story_data[i]['text'].replace('\\n','').replace('\\r','').lower()\n",
        "      # all_story_data[key].append(story_data[i]['text'].replace('\\n','').replace('\\r','').lower())\n",
        "      # full_story += story_data[i]['text'].replace('\\n','').replace('\\r','').lower() + ' <SEP> '\n",
        "\n",
        "\n",
        "    except:\n",
        "      print(\"---\", int(story_data[i]['section']), story_data[i] )\n",
        "\n",
        "  # REMOVE THE LAST <SEP>\n",
        "  full_story = full_story[:-6]\n",
        "\n",
        "  for i in question_data:\n",
        "    # it is possible one question is related to multiple sections \n",
        "    ##print(\"xx\", question_data[i])\n",
        "    \n",
        "    text_section_list = str(question_data[i]['cor_section']).split(\",\")\n",
        "    total_text = \"\"\n",
        "    if len(text_section_list) == 1:\n",
        "\n",
        "        question_data[i]['text'] = story_data_dict[int(question_data[i]['cor_section'])]\n",
        "        total_text = story_data_dict[int(question_data[i]['cor_section'])]\n",
        "    else:\n",
        "        \n",
        "        for j in text_section_list:\n",
        "            total_text += story_data_dict[int(j)].strip() + ' '\n",
        "\n",
        "        question_data[i]['text'] = total_text\n",
        "    \n",
        "\n",
        "    question = question_data[i]['question'].replace('\\n',' ').replace('\\r',' ').replace('\\t',' ').replace('\\s',' ').replace('\\t+',' ').replace('\\s+',' ').lower().strip(' ?') + ' ?'\n",
        "    attribute = question_data[i]['attribute1'].replace('\\n', '').lower()\n",
        "    ex_im = question_data[i]['ex-or-im1'].replace('\\n', '').lower()\n",
        "\n",
        "    # there's only one groundtruth answer\n",
        "    if split_version == 'train':\n",
        "      answer1 = question_data[i]['answer1'].replace('\\n',' ').replace('\\r',' ').replace('\\t',' ').replace('\\s',' ').replace('\\t+',' ').replace('\\s+',' ').lower().strip(' .') + ' .'\n",
        "      \n",
        "\n",
        "      doc = nlp(answer1)\n",
        "      tokenized = [token.text for token in doc]\n",
        "      answer1 = ' '.join(tokenized)\n",
        "      \n",
        "\n",
        "      all_question_data[key].append( total_text + ' </s> ' + question + ' </s> ' + answer1 )\n",
        "\n",
        "      all_A_output_data[key].append( answer1 )\n",
        "\n",
        "      all_QA_attribute[key].append( question + ' <SEP> ' + answer1 + ' <SEP> ' + attribute )\n",
        "      all_QA_ex_im[key].append( question + ' <SEP> ' + answer1 + ' <SEP> ' + ex_im )\n",
        "      all_QA_bias_analysis[key].append( total_text + ' <SEP> ' + question + ' <SEP> ' + answer1 + ' <SEP> ' + attribute + ' <SEP> ' + ex_im)\n",
        "    \n",
        "\n",
        "    # there are two groundtruth answers\n",
        "    if split_version == 'not_train':\n",
        "      answer1 = question_data[i]['answer1'].replace('\\n',' ').replace('\\r',' ').replace('\\t',' ').replace('\\s',' ').replace('\\t+',' ').replace('\\s+',' ').lower().strip(' .') + ' .'\n",
        "      answer2 = question_data[i]['answer4'].replace('\\n',' ').replace('\\r',' ').replace('\\t',' ').replace('\\s',' ').replace('\\t+',' ').replace('\\s+',' ').lower().strip(' .') + ' .'\n",
        "\n",
        "\n",
        "      doc = nlp(answer1)\n",
        "      tokenized = [token.text for token in doc]\n",
        "      answer1 = ' '.join(tokenized)\n",
        "\n",
        "      doc = nlp(answer2)\n",
        "      tokenized = [token.text for token in doc]\n",
        "      answer2 = ' '.join(tokenized)\n",
        "\n",
        "\n",
        "      all_question_data[key].append( total_text + ' </s> ' + question + ' </s> ' + answer1 + ' </s> ' + answer2 )\n",
        "      all_A_output_data[key].append( answer1 + ' </s> ' + answer2 )\n",
        "\n",
        "      all_A1_output_data[key].append( answer1 )\n",
        "      all_A2_output_data[key].append( answer2 )\n",
        "\n",
        "      all_QA_attribute[key].append( question + ' <SEP> ' + answer1 + ' </s> ' + answer2 + ' <SEP> ' + attribute )\n",
        "      all_QA_ex_im[key].append( question + ' <SEP> ' + answer1 + ' </s> ' + answer2 + ' <SEP> ' + ex_im )\n",
        "      all_QA_bias_analysis[key].append( total_text + ' <SEP> ' + question + ' <SEP> ' + answer1 + ' </s> ' + answer2 + ' <SEP> ' + attribute + ' <SEP> ' + ex_im)\n",
        "    \n",
        "    all_AC_input_data[key].append( answer1 + ' </s> ' + total_text )\n",
        "\n",
        "    all_Q_input_data[key].append( question )\n",
        "    all_C_input_data[key].append( total_text )\n",
        "\n",
        "    all_QC_input_data[key].append( question + ' <SEP> ' + total_text )\n",
        "\n",
        "    all_QS_input_data[key].append( question + ' <SEP> ' + full_story )\n",
        "  \n",
        "    all_CA_input_data[key].append( total_text + ' <SEP> ' + answer1 )\n",
        "    all_CQA_input_data[key].append( total_text + ' ' + question + ' <SEP> ' + answer1 )\n",
        "    \n",
        "    all_AC_ranking_input_data[key].append( answer1 + ' <SEP> ' + total_text )\n",
        "    all_QAC_input_data[key].append( question + ' <SEP> ' + answer1 + ' <SEP> ' + total_text )\n",
        "\n",
        "    all_spreadsheet_data[key].append( [ total_text, question, answer1 ] )\n",
        "\n",
        "    # remove nan key-value pairs in current instance in the dictionary\n",
        "    new_data_i = {}\n",
        "    for k in question_data[i].keys():\n",
        "        if not is_nan(question_data[i][k]):\n",
        "            new_data_i[k] = question_data[i][k]\n",
        "\n",
        "    total_data[key].append(new_data_i)\n",
        "\n",
        "    cnt_q += 1\n",
        "  cnt += 1\n",
        "\n",
        "\n",
        "print(\"# stories: \", cnt)\n",
        "print(\"# question: \", cnt_q)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VmyVJLQ9iue"
      },
      "source": [
        "#### Parse and store into different format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwrAUYqATonQ"
      },
      "outputs": [],
      "source": [
        "!mkdir ./pre-processed_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEFIZo8K9uul"
      },
      "source": [
        "data format to directly fine-tune a BART Question Answering model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64folLtNPKQm"
      },
      "outputs": [],
      "source": [
        "!mkdir ./pre-processed_data/BART_QA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k04zBibp1985"
      },
      "outputs": [],
      "source": [
        "if split_version == 'val':\n",
        "\n",
        "  f1 = open(\"./pre-processed_data/BART_QA/val.source\", \"w\")\n",
        "  f2 = open(\"./pre-processed_data/BART_QA/val_two_answer.target\", \"w\")\n",
        "\n",
        "if split_version == 'test':\n",
        "\n",
        "  f1 = open(\"./pre-processed_data/BART_QA/test.source\", \"w\")\n",
        "  f2 = open(\"./pre-processed_data/BART_QA/test_two_answer.target\", \"w\")\n",
        "\n",
        "for key in name_set:\n",
        "  for i in all_QC_input_data[key]:\n",
        "    f1.write( i.replace('\\n','').replace('\\r','') + '\\n' )\n",
        "  for i in all_A_output_data[key]:\n",
        "    f2.write( i.replace('\\n','').replace('\\r','') + '\\n' )\n",
        "\n",
        "f1.close()\n",
        "f2.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz69xfQXvsq5"
      },
      "source": [
        "data format to fine-tune a BART Question Generation model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_YMH909U7KO"
      },
      "outputs": [],
      "source": [
        "!mkdir ./pre-processed_data/BART_QG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH8XMpwX0W4e"
      },
      "outputs": [],
      "source": [
        "\n",
        "if split_version == 'val':\n",
        "\n",
        "  f1 = open(folder_dir + \"./pre-processed_data/BART_QG/val.source\", \"w\")\n",
        "  f2 = open(folder_dir + \"./pre-processed_data/BART_QG/val.target\", \"w\")\n",
        "\n",
        "if split_version == 'test':\n",
        "\n",
        "  f1 = open(folder_dir + \"./pre-processed_data/BART_QG/test.source\", \"w\")\n",
        "  f2 = open(folder_dir + \"./pre-processed_data/BART_QG/test.target\", \"w\")\n",
        "\n",
        "for key in name_set:\n",
        "  for i in all_AC_ranking_input_data[key]:\n",
        "    f1.write( i + '\\n' )\n",
        "  for i in all_Q_input_data[key]:\n",
        "    f2.write( i + '\\n' )\n",
        "\n",
        "f1.close()\n",
        "f2.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtzR-fMW9x6C"
      },
      "source": [
        "data format to be used for training an answer ranking model. need to be combined with generated QA-pairs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9r0zj0uYbNn"
      },
      "outputs": [],
      "source": [
        "!mkdir ./pre-processed_data/Ranking_QA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1V5cTsO9zm7"
      },
      "outputs": [],
      "source": [
        "\n",
        "f4 = open(\"./pre-processed_data/Ranking_QA/train_groundtruth_QAC.txt\", \"w\")\n",
        "\n",
        "for key in name_set:\n",
        "\n",
        "    for i in all_QAC_input_data[key]:\n",
        "        f4.write( i + '\\n' )\n",
        "        \n",
        "f4.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNaEb2HLMG0k"
      },
      "source": [
        "data format for generating QA-pairs with our system, each line is a section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_hZ4PaDOU1u"
      },
      "outputs": [],
      "source": [
        "!mkdir ./pre-processed_data/Ranking_QA/QA_generation\n",
        "!mkdir ./pre-processed_data/Ranking_QA/QA_generation/test\n",
        "!mkdir ./pre-processed_data/Ranking_QA/QA_generation/val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjGFvCLjMLXE"
      },
      "outputs": [],
      "source": [
        "if split_version == 'val':\n",
        "  for key in name_set:\n",
        "    f = open(\"./pre-processed_data/Ranking_QA/QA_generation/val\" + \"/sections-\" + key + \".txt\", \"w+\")\n",
        "    for i in all_story_data[key]:\n",
        "      f.write(i + '\\n')\n",
        "    f.close()\n",
        "\n",
        "if split_version == 'test':\n",
        "  for key in name_set:\n",
        "    f = open(\"./pre-processed_data/Ranking_QA/QA_generation/test\" + \"/sections-\" + key + \".txt\", \"w+\")\n",
        "    for i in all_story_data[key]:\n",
        "      f.write(i + '\\n')\n",
        "    f.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WTXQHIU-BLX"
      },
      "source": [
        "data format for evaluation, use as groundtruth file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCpaUDvoaASy"
      },
      "outputs": [],
      "source": [
        "!mkdir ./pre-processed_data/Ranking_QA/Evaluation_Groundtruth\n",
        "!mkdir ./pre-processed_data/Ranking_QA/Evaluation_Groundtruth/test\n",
        "!mkdir ./pre-processed_data/Ranking_QA/Evaluation_Groundtruth/val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxNW3BH3vtD_"
      },
      "outputs": [],
      "source": [
        "if split_version == 'val':\n",
        "\n",
        "  for key in name_set:\n",
        "    f = open(\"./pre-processed_data/Ranking_QA/Evaluation_Groundtruth/val/Evaluation_GT_stories-\" + key + \".txt\", \"w+\")\n",
        "    for i in all_question_data[key]:\n",
        "      f.write( i.replace('\\n','').replace('\\r','') + '\\n' )\n",
        "    f.close()\n",
        "\n",
        "if split_version == 'test':\n",
        "\n",
        "  for key in name_set:\n",
        "    f = open(\"./pre-processed_data/Ranking_QA/Evaluation_Groundtruth/test/Evaluation_GT_stories-\" + key + \".txt\", \"w+\")\n",
        "    for i in all_question_data[key]:\n",
        "      f.write( i.replace('\\n','').replace('\\r','') + '\\n' )\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OquUR7Vv4s5X"
      },
      "source": [
        "data format for training a baseline C -> Q model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIL3OX6L4ypj"
      },
      "outputs": [],
      "source": [
        "# f1 = open(\"/gdrive/MyDrive/NLP_Stage_2/Generation_Project/After_EMNLP/FairyTale/ACL_split/BASELINE_BART_CQ/train.source\", \"w\")\n",
        "# f2 = open(\"/gdrive/MyDrive/NLP_Stage_2/Generation_Project/After_EMNLP/FairyTale/ACL_split/BASELINE_BART_CQ/train.target\", \"w\")\n",
        "\n",
        "\n",
        "# for key in name_set:\n",
        "#     for i in all_C_input_data[key]:\n",
        "\n",
        "#         f1.write( i.replace('\\n','').replace('\\r','') + '\\n' )\n",
        "\n",
        "#     for i in all_Q_input_data[key]:\n",
        "\n",
        "#         f2.write( i.replace('\\n','').replace('\\r','') + '\\n' )\n",
        "\n",
        "\n",
        "# f1.close()\n",
        "# f2.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwr8EXGrM04O"
      },
      "source": [
        "data format to prepare input data for PAQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6_9Oxi3OATS"
      },
      "outputs": [],
      "source": [
        "# cnt = 0\n",
        "\n",
        "# with open(\"/gdrive/MyDrive/NLP_Stage_2/Generation_Project/After_EMNLP/FairyTale/ACL_split/BASELINE_PAQ/PAQ_input_stories-test.txt\", 'wt') as out_file:\n",
        "#     tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "    \n",
        "#     for key in name_set:\n",
        "#       for i in all_story_data[key]:\n",
        "#         tsv_writer.writerow([cnt, i.replace('\\n','').replace('\\r','').lower(), \"val\"])\n",
        "#         cnt += 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9bY_BjmTFkZ"
      },
      "outputs": [],
      "source": [
        "# print(cnt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "0. Pre-processing_the_original_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
