{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJooWIy6VyUm",
        "outputId": "f1d9f350-2347-45b7-bd5f-0b95f66c2422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Mar  7 20:14:39 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you haven't, Remember to follow the first step to pre-process the original data"
      ],
      "metadata": {
        "id": "zIY5TNwma4Ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WorkInTheDark/FairytaleQA_QAG_System.git\n",
        "%cd ./FairytaleQA_QAG_System/"
      ],
      "metadata": {
        "id": "RH9n0VoZbhrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM9pPo5XHaxX"
      },
      "outputs": [],
      "source": [
        "\n",
        "%cd ./transformers\n",
        "!pip install -e \".[testing]\"\n",
        "!pip install -r ./examples/requirements.txt\n",
        "%cd ./.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "0tnhU9XtvlH5",
        "outputId": "d6af371d-d45b-4f9d-d1be-54b772079745"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-bca0e2660b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
          ]
        }
      ],
      "source": [
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPbWcskaIZK1"
      },
      "outputs": [],
      "source": [
        "!pip install torchtext==0.8.0 torch==1.7.1 pytorch-lightning==1.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-TMSdd9Kw5k"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_lightning==0.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7QCUrKyHzHX",
        "outputId": "c8f2d538-fd61-4bf6-9df0-0a784985a763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/CQ_A_book_movie_summary_Mou\n"
          ]
        }
      ],
      "source": [
        "%cd ./FairytaleQA_QAG_System/Fine-tune_BART"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VgjE_SAHvBw"
      },
      "source": [
        "##### train from narrativeQA ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuTo50QbJoHE"
      },
      "outputs": [],
      "source": [
        "# %%shell\n",
        "\n",
        "# python 1_train.py \\\n",
        "#     --data_dir=./data/       \\\n",
        "#     --model_name_or_path=facebook/bart-large        \\\n",
        "#     --tokenizer_name=facebook/bart-large            \\\n",
        "#     --config_name=facebook/bart-large               \\\n",
        "#     --ckpt_path= PATH_TO_CKPT/epoch=4.ckpt       \\\n",
        "#     --do_train                 \\\n",
        "#     --gpus=1                     \\\n",
        "#     --max_epochs=2                \\\n",
        "#     --learning_rate=5e-6                   \\\n",
        "#     --train_batch_size=1                            \\\n",
        "#     --max_target_length=900                         \\\n",
        "#     --val_max_target_length=900                     \\\n",
        "#     --test_max_target_length=900                    \\\n",
        "#     --eval_batch_size=1                             \\\n",
        "#     --cache_dir=./pretrained/                          \\\n",
        "#     --output_dir=./output\n",
        " \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxjNH9_8An_u"
      },
      "source": [
        "##### train from pretrained-bart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDREnLaeAtFX"
      },
      "source": [
        "QA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLysRAnmBqzK"
      },
      "outputs": [],
      "source": [
        "# %%shell\n",
        "\n",
        "# python 1_train.py \\\n",
        "#     --data_dir=./data/BART_QA/       \\\n",
        "#     --model_name_or_path=facebook/bart-large        \\\n",
        "#     --tokenizer_name=facebook/bart-large            \\\n",
        "#     --config_name=facebook/bart-large               \\\n",
        "#     --do_train                 \\\n",
        "#     --gpus=1                     \\\n",
        "#     --max_epochs=2                \\\n",
        "#     --learning_rate=5e-6                   \\\n",
        "#     --train_batch_size=1                            \\\n",
        "#     --max_target_length=900                         \\\n",
        "#     --val_max_target_length=900                     \\\n",
        "#     --test_max_target_length=900                    \\\n",
        "#     --eval_batch_size=1                             \\\n",
        "#     --cache_dir=./pretrained/                          \\\n",
        "#     --output_dir=./output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv ./output/epoch=1.ckpt ./output/finetuned_CQ_A_on_FairyTale_only_5e-6_b1_epoch=1.ckpt"
      ],
      "metadata": {
        "id": "iAGbloi8hFlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8lbhk_YAvFA"
      },
      "source": [
        "QG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YmXdb_QlAv_l"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "python 1_train.py \\\n",
        "    --data_dir=./data/BART_QG/       \\\n",
        "    --model_name_or_path=facebook/bart-large        \\\n",
        "    --tokenizer_name=facebook/bart-large            \\\n",
        "    --config_name=facebook/bart-large               \\\n",
        "    --do_train                 \\\n",
        "    --gpus=1                     \\\n",
        "    --max_epochs=4                \\\n",
        "    --learning_rate=5e-6                   \\\n",
        "    --train_batch_size=1                            \\\n",
        "    --max_target_length=900                         \\\n",
        "    --val_max_target_length=900                     \\\n",
        "    --test_max_target_length=900                    \\\n",
        "    --eval_batch_size=1                             \\\n",
        "    --cache_dir=./pretrained/                          \\\n",
        "    --output_dir=./output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./output/epoch=3.ckpt ./output/finetuned_BART_AC_Q_FairyTale_only_5e-6_b1_epoch=3.ckpt"
      ],
      "metadata": {
        "id": "77WS_R_pg85Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "1VgjE_SAHvBw"
      ],
      "machine_shape": "hm",
      "name": "1. Train_BART_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}